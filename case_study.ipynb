{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeec8b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User variables\n",
    "SAVE_ELEMENTS = True # True if figures and models shall be saved\n",
    "\n",
    "MAX_DURATION_JOURNEY = 180\n",
    "\n",
    "COMPUTE_DFG = True\n",
    "COMPUTE_SEQUENCE = True\n",
    "COMPUTE_SEQUENCE_DISTANCE = False\n",
    "N_PROCESSORS = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e43f412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "from networkx.drawing.nx_agraph import to_agraph\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "import copy\n",
    "from collections import Counter\n",
    "import subprocess\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "from multiprocessing import Pool\n",
    "import itertools\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b98f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERIFYTA_PATH = \"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a6a336c",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "The data is loaded and preprocessed.\n",
    "Names of events are parsed and unused events are removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f31a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes unused events and parses event names\n",
    "def process_touchpoint_names(df):\n",
    "    print(\"Found types\", set(df['Type']))\n",
    "    running_df = df[df['Type'].isin(['state', 'feedback','subject', 'task', 'resultsShared'])].copy()\n",
    "    #prelims = df[df['concept:name'].str.contains(\"Preliminary results updated for overall score\")] # include prelim results - doesnt make a lot of sense...\n",
    "    #running_df = running_df.append(prelims)\n",
    "    running_df['concept:name'] = running_df['concept:name'].str.replace('\\n', \"\") # rows might contain line-breaks; for different A, B, C tasks\n",
    "    running_df['concept:name'] = running_df['concept:name'].str.replace(r\"loggedIn.*\",\"loggedIn\") # removes feedback attributes\n",
    "    running_df['concept:name'] = running_df['concept:name'].str.replace(r\"\\[.*\\]\",\"\") # removes feedback attributes\n",
    "    running_df['concept:name'] = running_df['concept:name'].str.replace(\",\", \"\")\n",
    "    running_df['concept:name'] = running_df['concept:name'].str.split('version').str[0]\n",
    "    \n",
    "    running_df['concept:name'] = running_df['concept:name'].str.split('Time used').str[0]\n",
    "\n",
    "    running_df['concept:name'] = running_df['concept:name'].str.split('taskDownloaded').str[0]\n",
    "\n",
    "    running_df['concept:name'] = running_df['concept:name'].str.split('testCompleted').str[0]\n",
    "\n",
    "    running_df['concept:name'] = running_df['concept:name'].str.split('itemCompleted').str[0]\n",
    "\n",
    "    running_df['concept:name'] = running_df['concept:name'].str.strip()\n",
    "\n",
    "    m = running_df['concept:name'].str.contains(\"survey:\")\n",
    "    running_df.loc[m, 'concept:name'] = running_df['concept:name'][m].str.split('survey: ').str[1]\n",
    "    \n",
    "    m = running_df['Type'] == 'state'\n",
    "    running_df.loc[m, 'concept:name'] = running_df['concept:name'][m].values\n",
    "    running_df.loc[~m, 'concept:name'] = running_df['concept:name'][~m].values\n",
    "    return running_df\n",
    "\n",
    "# Filters the dataset to only contain traces with length in [lower_bound, upper_bound]\n",
    "def get_filtered_df(path, lower_bound = 15, upper_bound = 60):\n",
    "    df = pd.read_csv(path, sep = \";\")\n",
    "    log_csv = df.sort_values('Timestamp', kind = \"stable\")\n",
    "    #log_csv = dataframe_utils.convert_timestamp_columns_in_df(log_csv)\n",
    "\n",
    "    developers_finished_ids = set(log_csv[log_csv['Message'] == \"finished\"]['Developer ID'].sort_values(kind = \"stable\").values)\n",
    "\n",
    "    #rename columns to process mining notation\n",
    "    log_csv.rename(columns={'Developer ID': 'case:DeveloperID', 'Message' : 'concept:name', 'Timestamp':'time:timestamp'}, inplace=True)\n",
    "    log_csv['time:timestamp'] = pd.to_datetime(log_csv['time:timestamp'], unit='s')\n",
    "    \n",
    "    # process touchpoint names\n",
    "    developers_df = process_touchpoint_names(log_csv)\n",
    "\n",
    "    #filter used logs\n",
    "    developers_df = developers_df.groupby(['case:DeveloperID']).filter(lambda x: len(x) >= lower_bound and len(x) <= upper_bound)\n",
    "\n",
    "    unsuccesfull = developers_df[~developers_df['case:DeveloperID'].isin(list(developers_finished_ids))]['case:DeveloperID'].value_counts().to_list()\n",
    "    succesfull = developers_df[developers_df['case:DeveloperID'].isin(list(developers_finished_ids))]['case:DeveloperID'].value_counts().to_list()\n",
    "    plt.scatter(range(len(unsuccesfull)), unsuccesfull, c = \"r\", s = 7)\n",
    "    plt.scatter(range(len(unsuccesfull),len(unsuccesfull)+(len(succesfull))), succesfull, c = \"b\", s = 7)\n",
    "    plt.xlabel(\"Journeys\")\n",
    "    plt.ylabel(\"Length\")\n",
    "    plt.show()\n",
    "    print(\"Includes #unsuccesfull:\", len(unsuccesfull),\"and #succesfull\", len(succesfull))\n",
    "    \n",
    "    print(\"Histograms\")\n",
    "    sns.displot(data=pd.DataFrame({\"Journey Length - Successfull\": succesfull}),\n",
    "            x=\"Journey Length - Successfull\", color='blueviolet', height=3)\n",
    "    plt.show()\n",
    "    \n",
    "    sns.displot(data=pd.DataFrame({\"Journey Length - Unsuccessfull\": unsuccesfull}),\n",
    "            x=\"Journey Length - Unsuccessfull\", color='blueviolet', height=3)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    developers_df = developers_df.sort_values(by=['time:timestamp'], kind = \"stable\")\n",
    "\n",
    "    return developers_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357eff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df_single = get_filtered_df(\"data.csv\")\n",
    "s1 = set(filtered_df_single[\"concept:name\"])\n",
    "\n",
    "started = filtered_df_single[filtered_df_single[\"concept:name\"]==\"registered\"]\n",
    "times = started[\"time:timestamp\"]\n",
    "print(min(times), max(times)) # two years\n",
    "print(max(times)-min(times), (max(times)-min(times)).total_seconds())\n",
    "WINDOW_SIZE = (max(times)-min(times)).total_seconds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a598e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = get_filtered_df(\"data_extended.csv\")\n",
    "s2 = set(filtered_df[\"concept:name\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de8f3958",
   "metadata": {},
   "source": [
    "## Investigate starting time-stamp\n",
    "We plot the companies, duration of all single journeys.\n",
    "Additionally, we generate a histogram over the number of users starting at a certain time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c810212e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(filtered_df.head())\n",
    "times = {}\n",
    "companies = {}\n",
    "developers = set(filtered_df['case:DeveloperID'])\n",
    "\n",
    "for d in developers:\n",
    "    reduced = filtered_df[filtered_df['case:DeveloperID']==d]\n",
    "    assert(len(set(reduced[\"Company ID\"])) == 1)\n",
    "    companies[d] = list(set(reduced[\"Company ID\"]))[0]\n",
    "    times[d] = (min(reduced[\"time:timestamp\"]), max(reduced[\"time:timestamp\"]))\n",
    "\n",
    "number_companies = len(set(companies.values()))\n",
    "company_iterator = {c : i for c,i in zip(set(companies.values()), range(number_companies))}\n",
    "print(\"number companies\", number_companies)\n",
    "\n",
    "sorted_times = sorted(times.items(), key=lambda item: item[1])\n",
    "\n",
    "count = 0\n",
    "for t in sorted_times:\n",
    "    company_it = company_iterator[companies[t[0]]]\n",
    "    plt.plot([t[1][0],t[1][1]], [count, count], c=sns.color_palette(\"hls\", number_companies)[company_it])\n",
    "    count += 1\n",
    "plt.title(\"Duration of journeys, colored by company\")\n",
    "plt.show()\n",
    "\n",
    "started = filtered_df[filtered_df[\"concept:name\"]==\"registered\"]\n",
    "starting_times = started[\"time:timestamp\"]\n",
    "end_times = filtered_df.groupby(['case:DeveloperID']).max()[\"time:timestamp\"]\n",
    "print(min(starting_times), max(starting_times)) # two years\n",
    "plt.hist(starting_times, 48)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cd676a",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diffs = []\n",
    "for t in times.values():\n",
    "    time_diffs.append((t[1]-t[0]).days)\n",
    "\n",
    "plt.hist(time_diffs, 20)\n",
    "plt.title(\"Durations of recorded journeys.\")\n",
    "plt.show()\n",
    "\n",
    "print(len([t for t in time_diffs if t > 21]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0da2df48",
   "metadata": {},
   "source": [
    "# Build log\n",
    "The dataset is flattened to a log structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2312abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "success_states = ['finished']\n",
    "# A log consists of traces, where each trace contains all elements from one developer \n",
    "def build_log(df, return_start_times = False, return_execution_times = False):\n",
    "    log = []\n",
    "    start_times = [] # maps from developer to timestamp\n",
    "    execution_times = []\n",
    "    running_df = df.copy()\n",
    "    print(running_df['time:timestamp'].dtype)\n",
    "    #running_df['time:timestamp'] = running_df['time:timestamp'].to_datetime()\n",
    "    running_df = running_df.sort_values(by=['time:timestamp'], kind = \"stable\")\n",
    "    print(running_df.head(20))\n",
    "    developers_id = set(running_df['case:DeveloperID'].values)\n",
    "    for dev_id in developers_id:\n",
    "        current_trace = running_df[running_df['case:DeveloperID'] == dev_id]['concept:name'].values\n",
    "        current_times = running_df[running_df['case:DeveloperID'] == dev_id]['time:timestamp'].values\n",
    "\n",
    "        trace_start = min(running_df[running_df['case:DeveloperID'] == dev_id]['time:timestamp'])\n",
    "        trace_end = max(running_df[running_df['case:DeveloperID'] == dev_id]['time:timestamp'])\n",
    "\n",
    "        if ((trace_end-trace_start).days > MAX_DURATION_JOURNEY):\n",
    "            print(\"omitted developer\", dev_id, \"due to length\")\n",
    "            continue\n",
    "        \n",
    "        # add unique start node \"start\"\n",
    "        current_trace = np.insert(current_trace,0,\"start\")\n",
    "        current_times = np.insert(current_times,0,current_times[0])\n",
    "        # attach final node finPos / finNeg\n",
    "        if(any(s in current_trace for s in success_states)):\n",
    "            current_trace = np.append(current_trace,\"finPos\")\n",
    "            current_times = np.append(current_times,current_times[-1])\n",
    "        else:\n",
    "            current_trace = np.append(current_trace,\"finNeg\")\n",
    "            current_times = np.append(current_times,current_times[-1])\n",
    "        log.append(current_trace)\n",
    "        start_times.append(min(running_df[running_df['case:DeveloperID'] == dev_id]['time:timestamp']))\n",
    "        execution_times.append(current_times)\n",
    "        assert(len(log[-1]) == len(execution_times[-1]))\n",
    "    assert(len(log) == len(execution_times))\n",
    "\n",
    "    # alter \"logged in: Web page\" to determine phase of journey:\n",
    "    # Phase (1) sign up, (2) solve all programming tasks, and  (3) review and share the skill report with the customer.\n",
    "    for t in log:\n",
    "        indices = [i for i, x in enumerate(t) if x == \"Logged in: Web page\"]\n",
    "        for i in indices:\n",
    "            t[i] = \"Logged in: Web page - Sign up\"\n",
    "            result = np.where(t == \"Task event:\")\n",
    "            if \"Task event:\" in t and result[0][0] < i:\n",
    "                t[i] = \"Logged in: Web page - Task\"\n",
    "            result = np.where(t == \"waitingForResultApproval\")\n",
    "            if \"waitingForResultApproval\" in t and result[0][0] < i:\n",
    "                t[i] = \"Logged in: Web page - Approval\"\n",
    "                \n",
    "    # add task number\n",
    "    for t in log:\n",
    "        indices_feedback = [i for i, x in enumerate(t) if x == \"Give feedback\"]\n",
    "        indices_task = [i for i, x in enumerate(t) if x == \"Task event:\"]\n",
    "        for i in indices_task:\n",
    "            count_indices = [j for j in indices_feedback if j < i] # uses feedback to increase task counter after giving feedback\n",
    "            t[i] += \" \"+str(len(count_indices))\n",
    "    # add feedback number        \n",
    "    for t in log:\n",
    "        indices_feedback = [i for i, x in enumerate(t) if x == \"Give feedback\"]\n",
    "        indices_task = [i for i, x in enumerate(t) if x == \"Task event:\"]\n",
    "        for i in indices_feedback:\n",
    "            count_indices = [j for j in indices_feedback if j < i]\n",
    "            t[i] += \" \"+str(len(count_indices))\n",
    "    \"\"\"\n",
    "    # add number to log in:\n",
    "    for t in log:\n",
    "        indices_feedback = [i for i, x in enumerate(t) if x == \"Give feedback\"]\n",
    "        indices_loggin = [i for i, x in enumerate(t) if x == \"Task event: loggedIn\"]\n",
    "        for i in indices_loggin:\n",
    "            count_indices = [j for j in indices_feedback if j < i]\n",
    "            t[i] += \" \"+str(len(count_indices))\n",
    "    \"\"\"\n",
    "\n",
    "    if return_start_times:\n",
    "        if return_execution_times:\n",
    "            return log, start_times, execution_times\n",
    "        else:\n",
    "            return log, start_times\n",
    "    else:\n",
    "        if return_execution_times:\n",
    "            return log, execution_times\n",
    "        else:\n",
    "            return log\n",
    "\n",
    "def isInTrace(s,t, trace):\n",
    "    for i in range(len(trace)-1):\n",
    "        if trace[i] == s and trace[i+1] == t:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702dd341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_doubles(log, execution_times = []):\n",
    "    filtered_log = []\n",
    "    filtered_execution_times = []\n",
    "    for index in range(len(log)):\n",
    "        # remove sequential same elements\n",
    "        trace = log[index]\n",
    "        current_trace = [trace[0]]\n",
    "        if execution_times:\n",
    "            current_times = [execution_times[index][0]]\n",
    "        for pos in range(1,len(trace)):\n",
    "            if trace[pos]==trace[pos-1]:\n",
    "                continue\n",
    "            current_trace.append(trace[pos])\n",
    "            if execution_times:\n",
    "                current_times.append(execution_times[index][pos])\n",
    "\n",
    "        filtered_log.append(current_trace)\n",
    "        if execution_times:\n",
    "            filtered_execution_times.append(current_times)\n",
    "    if execution_times == []:\n",
    "        return filtered_log\n",
    "    return filtered_log, filtered_execution_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fc6c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ignore_loggin(log, execution_times = []):\n",
    "    filtered_log = []\n",
    "    filtered_execution_times = []\n",
    "    for index in range(len(log)):\n",
    "        # remove sequential same elements\n",
    "        trace = log[index]\n",
    "        current_trace = [trace[0]]\n",
    "        if execution_times:\n",
    "            current_times = [execution_times[index][0]]\n",
    "        for pos in range(1,len(trace)):\n",
    "            if \"Task event: loggedIn\" in trace[pos] or \"Logged in: Web page\" in trace[pos]:\n",
    "                continue\n",
    "            current_trace.append(trace[pos])\n",
    "            if execution_times:\n",
    "                current_times.append(execution_times[index][pos])\n",
    "\n",
    "        filtered_log.append(current_trace)\n",
    "        if execution_times:\n",
    "            filtered_execution_times.append(current_times)\n",
    "    if execution_times == []:\n",
    "        return filtered_log\n",
    "    return filtered_log, filtered_execution_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dba2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "log, start_times, execution_times = build_log(filtered_df, return_start_times=True, return_execution_times=True)\n",
    "log, execution_times = ignore_loggin(log, execution_times)\n",
    "log, execution_times = filter_doubles(log, execution_times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4701927d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Variants before removing trivial elements\")\n",
    "print(log)\n",
    "print(len(Counter(str(e) for e in log).keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1073e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_single, single_start_times, single_execution_times = build_log(filtered_df_single, return_start_times=True, return_execution_times=True)\n",
    "log_single, single_execution_times = ignore_loggin(log_single, single_execution_times)\n",
    "log_single, single_execution_times = filter_doubles(log_single, single_execution_times)\n",
    "print(log_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72ad44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# variants in log\n",
    "print(\"Variants before removing trivial elements\")\n",
    "variants_counter = Counter(str(e) for e in log)\n",
    "plt.hist(variants_counter.values(), 10)\n",
    "print(len(Counter(str(e) for e in log).keys()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d7a7268",
   "metadata": {},
   "source": [
    "# Create DFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ed1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Builds the directly follows graph according to the log\n",
    "# Removes all edges which are traversed less than \"threshold\" times\n",
    "def build_dfg(log, threshold):\n",
    "    states = list(set([item for sublist in log for item in sublist])) # flatten list\n",
    "\n",
    "    edges = []\n",
    "    edge_counter = {}\n",
    "    for trace in log:\n",
    "        s = \"start\"\n",
    "        assert(trace[0]==\"start\")\n",
    "        for pos in trace[1:]:\n",
    "            t = pos\n",
    "            e = (s,t)\n",
    "            if e not in edges:\n",
    "                edges.append(e)\n",
    "                edge_counter[e] = 1\n",
    "            else:\n",
    "                edge_counter[e] = edge_counter[e]+1\n",
    "            s = t\n",
    "    \n",
    "    g = nx.DiGraph()\n",
    "    g.add_nodes_from(states)\n",
    "    max_val = max(edge_counter.values())\n",
    "    for e in edges:\n",
    "        g.add_edge(e[0], e[1], edge_weight = edge_counter[e]/max_val) # adds \"thickness\" element\n",
    "\n",
    "    # remove all simple loops & rarely traversed edges\n",
    "    to_remove = []\n",
    "    for e in g.edges:\n",
    "        if e[0] == e[1]:\n",
    "            to_remove.append(e)\n",
    "        if edge_counter[e] <= threshold:\n",
    "            to_remove.append(e)\n",
    "\n",
    "    for e in to_remove:\n",
    "        if e in g.edges():\n",
    "            g.remove_edge(e[0],e[1])\n",
    "            \n",
    "    \n",
    "    # remove isolated nodes\n",
    "    g.remove_nodes_from(list(nx.isolates(g)))\n",
    "    \n",
    "    return g\n",
    "\n",
    "def draw_dfg(g, name):\n",
    "    # build graph with variable thicknes\n",
    "    scaling = 10/np.mean(list(nx.get_edge_attributes(g,'edge_weight').values()))\n",
    "\n",
    "    A = to_agraph(g)\n",
    "    edge_weights = nx.get_edge_attributes(g,'edge_weight')\n",
    "\n",
    "    for e in edge_weights:\n",
    "        e = A.get_edge(e[0], e[1])\n",
    "        #e.attr[\"penwidth\"] = edge_weights[e]*scaling\n",
    "        e.attr[\"fontsize\"] = \"20\"\n",
    "        if 'controllable' in g.nodes[e[1]]:\n",
    "            if not g.nodes[e[1]]['controllable']:\n",
    "                e.attr[\"style\"] = \"dotted\"\n",
    "    for e in g.edges:\n",
    "        e = A.get_edge(e[0], e[1])\n",
    "        if 'controllable' in g.edges[e]:\n",
    "            if not g.edges[e]['controllable']:\n",
    "                e.attr[\"style\"] = \"dotted\"\n",
    "        #A.add_edge(e[0], e[1], penwidth = edge_weights[e]*scaling)\n",
    "\n",
    "    #A.graph_attr.update(size=\"7.75,10.25\")\n",
    "    A.layout(\"dot\")\n",
    "    if SAVE_ELEMENTS:\n",
    "        A.draw(name)\n",
    "    print(\"plotted\", name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33d000e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = build_dfg(log_single, 0)\n",
    "draw_dfg(g, \"graph.ps\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b00e1454",
   "metadata": {},
   "source": [
    "# Burnd-Down Chart of Developers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c169dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw the burn down chart of developers leaving the journey per touchpoint, Figure 6\n",
    "def draw_burn_down(g,s, t, log):\n",
    "    g_copy = copy.deepcopy(g)\n",
    "    edge_counter = {}\n",
    "    node_counter = {}\n",
    "    \n",
    "    for trace in log:\n",
    "        s = \"start\"\n",
    "        assert(trace[0]==\"start\")\n",
    "        for pos in trace[1:]:\n",
    "            t = pos\n",
    "            e = (s,t)\n",
    "            if e not in edge_counter:\n",
    "                edge_counter[e] = 1\n",
    "            else:\n",
    "                edge_counter[e] = edge_counter[e]+1\n",
    "            s = t\n",
    "            \n",
    "    for trace in log:\n",
    "        for pos in set(trace):\n",
    "            if pos in node_counter:\n",
    "                node_counter[pos] = node_counter[pos]+1\n",
    "            else:\n",
    "                node_counter[pos] = 1\n",
    "            continue\n",
    "\n",
    "    for e in edge_counter:\n",
    "        if e[1] == \"finNeg\":\n",
    "            print(e, edge_counter[e])\n",
    "    \n",
    "    x = [100,81, 72, 64, 52]\n",
    "    y = [\"start\", \"T10\", \"T12\", \"T14\", \"T25\"]\n",
    "    x2 = [0,18,9,9,12]\n",
    "    y2 = [\"start\", \"T10\", \"T12\", \"T14\", \"T25\"]\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_axes([0,0,1,1])\n",
    "    ax.plot(y,x, 'o-')\n",
    "    ax.bar(y2, x2, color=\"r\")\n",
    "    plt.ylabel(\"Developers (in %)\", fontsize=18)\n",
    "    plt.xlabel(\"Events\", fontsize=18)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4991b213",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_burn_down(g, \"start\", \"finNeg\", log_single)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "257e6f04",
   "metadata": {},
   "source": [
    "# DFG to Customer Journey Game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d9214a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load actors from given file\n",
    "# The file maps events to actors in xml format\n",
    "# Every unspecified event is controllable\n",
    "with open('activities.xml') as f:\n",
    "    data = f.read()\n",
    "actors = json.loads(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f32ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stores actors in graph\n",
    "def extend_graph_with_actors(g, actors, transition_system=False):\n",
    "    if not transition_system:\n",
    "        for node in g.nodes:\n",
    "            if node not in actors:\n",
    "                g.nodes[node]['controllable'] = True\n",
    "            else:\n",
    "                g.nodes[node]['controllable'] = actors[node] == \"company\"\n",
    "    else:\n",
    "        for e in g.edges:\n",
    "            controllable_set = False\n",
    "            for key in actors:\n",
    "                if key in g.edges[e]['action']:\n",
    "                    controllable_set = True\n",
    "                    g.edges[e]['controllable'] = actors[key] == 'company'\n",
    "            if not controllable_set:\n",
    "                g.edges[e]['controllable'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a08a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "extend_graph_with_actors(g, actors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b623a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper functions to compute weights for edges\n",
    "\n",
    "def isInTrace(s,t, trace):\n",
    "    for i in range(len(trace)-1):\n",
    "        if trace[i] == s and trace[i+1] == t:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def weight(trace):\n",
    "    return 1 if any(\"finished\" in pos for pos in trace) else -1\n",
    "\n",
    "def majority(s,t,log):\n",
    "    maj = 0\n",
    "    for trace in log:\n",
    "        if isInTrace(s,t,trace):\n",
    "            maj += weight(trace)\n",
    "    return 1 if maj == 0 else int(maj/abs(maj))\n",
    "\n",
    "def entropy(p1, p2):\n",
    "    if p1 == 0 or p2 == 0:\n",
    "        return 0\n",
    "    return - p1*np.log2(p1) - p2* np.log2(p2)\n",
    "\n",
    "def distribution(s,t,log, edge_mapping = []):\n",
    "    distr = {1.0: 0 , -1.0 : 0}\n",
    "    if edge_mapping == []: # old function\n",
    "        for trace in log:\n",
    "            if isInTrace(s,t,trace):\n",
    "                w = weight(trace)\n",
    "                distr[w] += 1\n",
    "    else:# use abstraction\n",
    "        assert((s,t) in edge_mapping)\n",
    "        for trace_index in set(edge_mapping[(s,t)]):\n",
    "            w = weight(log[trace_index])\n",
    "            distr[w] += 1 #\n",
    "    return distr[1], distr[-1]\n",
    "\n",
    "def compute_edge_cost(g, log, edge_mapping = []):\n",
    "    weights = [1 if \"finished\" in i else -1 for i in log]\n",
    "    edge_cost = {}\n",
    "    for s in g.nodes:\n",
    "        for t in g[s]:\n",
    "            p1, p2 = distribution(s,t,log, edge_mapping)\n",
    "            if p1 +  p2 == 0:\n",
    "                assert(False)\n",
    "            wp1 = p1/(p1+p2)\n",
    "            wp2 = p2/(p1+p2)\n",
    "            #w = majority(s,t,log)\n",
    "            w = 1 if p1 >= p2 else -1\n",
    "            scaling = 10\n",
    "            edge_cost[(s,t)] = (((1-entropy(wp1,wp2)) * w) -0.1 )*20\n",
    "    print(\"Edge cost was computed\")\n",
    "    return edge_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19118ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_cost = compute_edge_cost(g, log_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7630914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# annotates graph with cost-labels\n",
    "def annotate_graph(g, edge_cost):\n",
    "    for e in edge_cost:\n",
    "        g[e[0]][e[1]]['label'] = round(edge_cost[e],2)\n",
    "    return g\n",
    "\n",
    "# Colors graph labels green/red depending of the weight is positive or negative\n",
    "def color_graph(g):\n",
    "    g = copy.deepcopy(g)\n",
    "    for e in g.edges:\n",
    "        if g[e[0]][e[1]]['label'] > 0:\n",
    "            g[e[0]][e[1]]['color'] =\"darkgreen\"\n",
    "        if g[e[0]][e[1]]['label'] < 0:\n",
    "            g[e[0]][e[1]]['color'] =\"red\"\n",
    "    \n",
    "    return g\n",
    "\n",
    "# Plots clustered DFG, Figure 5\n",
    "def draw_dfg_clustered(g, name):\n",
    "    # build graph with variable thicknes\n",
    "    scaling = 10/np.mean(list(nx.get_edge_attributes(g,'edge_weight').values()))\n",
    "\n",
    "    g.graph['graph']={'rankdir':'LR'}\n",
    "\n",
    "    A = to_agraph(g)\n",
    "    edge_weights = nx.get_edge_attributes(g,'edge_weight')\n",
    "\n",
    "    for e in edge_weights:\n",
    "        e = A.get_edge(e[0], e[1])\n",
    "        e.attr[\"penwidth\"] = edge_weights[e]*scaling\n",
    "        e.attr[\"fontsize\"] = 70\n",
    "        if 'controllable' in g.nodes[e[1]]:\n",
    "            if not g.nodes[e[1]]['controllable']:\n",
    "                e.attr[\"style\"] = \"dotted\"\n",
    "\n",
    "    for n in A.nodes():\n",
    "        n.attr['fontsize'] = 80\n",
    "    #onboarding = [\"T\"+str(i) for i in range(0,6)]\n",
    "    #A.add_subgraph(onboarding, name='cluster_onboarding', label= \"Sign-up\", color = \"orange\", fontsize = 60, fontcolor = \"orange\")\n",
    "    task = [\"T\"+str(i) for i in range(6,21)]\n",
    "    #task = [k for k in naming if naming[k] in task ]\n",
    "    A.add_subgraph(task, name='cluster_task', label= \"Solve tasks\", color = \"blue\", fontsize = 60, fontcolor = \"blue\")\n",
    "    evaluation = [\"T\"+str(i) for i in range(21,27)]\n",
    "    #evaluation = [k for k in naming if naming[k] in evaluation ]\n",
    "    A.add_subgraph(evaluation, name='cluster_evaluation', label= \"Review and share\", color = \"purple\", fontsize = 60, fontcolor = \"purple\")\n",
    "\n",
    "    reversed_naming = {naming[i] : i for i in naming}\n",
    "    for n in A.nodes():\n",
    "        if n not in reversed_naming:\n",
    "            continue\n",
    "        n.attr['label'] = n#reversed_naming[n]\n",
    "    A.layout(\"dot\")\n",
    "    if SAVE_ELEMENTS:\n",
    "        A.draw(name)\n",
    "        \n",
    "# Introduced naming for readable function\n",
    "naming = {\n",
    "    \"registered\" : \"T0\",\n",
    "    \"activated\": \"T1\",\n",
    "    \"Logged in: Web page - Sign up\" : \"T2\",\n",
    "    \"vpcCreateUserOnInstance\" : \"T3\",\n",
    "    \"vpcAssignInstance\" : \"T4\",\n",
    "    \"readyToStart\" : \"T5\",\n",
    "    \"Task event: loggedIn\" : \"T6\",\n",
    "    \"started\" : \"T7\",\n",
    "    \"Task event: 0\": \"T8\",\n",
    "    \"Give feedback 0\" : \"T9\",\n",
    "    \"Task event: 1\": \"T10\",\n",
    "    \"Give feedback 1\" : \"T11\",\n",
    "    \"Task event: 2\": \"T12\",\n",
    "    \"Give feedback 2\" : \"T13\",\n",
    "    \"Task event: 3\": \"T14\",\n",
    "    \"Give feedback 3\" : \"T15\",\n",
    "    \"Task event: 4\": \"T16\",\n",
    "    \"Give feedback 4\" : \"T17\",\n",
    "    \"Task event: 5\": \"T18\",\n",
    "    \"waitingForManualScores\" : \"T19\",\n",
    "    \"Logged in: Web page - Task\" : \"T20\",\n",
    "    \"waitingForScores\" : \"T21\",\n",
    "    \"waitingForResultApproval\" : \"T22\",\n",
    "    \"waitingForSubjectAcceptance\" : \"T23\",\n",
    "    \"subjectAcceptanceReceived\" : \"T24\",\n",
    "    \"Results automatically shared\" : \"T24\",\n",
    "    \"waitingForActivityReport\" : \"T25\",\n",
    "    \"Logged in: Web page - Approval\" : \"T26\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565c2244",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in g.nodes:\n",
    "    print(n)\n",
    "\n",
    "g = annotate_graph(g, edge_cost)\n",
    "g_outgoing = color_graph(g)\n",
    "\n",
    "g_outgoing.remove_node(\"Results shared\")\n",
    "g_outgoing.remove_node(\"start\")\n",
    "g_outgoing.remove_node(\"registered\")\n",
    "g_outgoing.remove_node(\"activated\")\n",
    "g_outgoing.remove_node(\"vpcCreateUserOnInstance\")\n",
    "g_outgoing.remove_node(\"vpcAssignInstance\")\n",
    "g_outgoing.remove_node(\"readyToStart\")\n",
    "g_outgoing.remove_node(\"started\")\n",
    "g_outgoing.remove_node(\"waitingForManualScores\")\n",
    "\n",
    "g_outgoing = nx.relabel_nodes(g_outgoing, naming)\n",
    "\n",
    "g_outgoing.remove_edges_from(nx.selfloop_edges(g_outgoing)) # T24 introduces self loop\n",
    "draw_dfg_clustered(g_outgoing, 'outgoing_clustered.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e48a7373",
   "metadata": {},
   "source": [
    "# Mapping to UPPAAL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38299ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes all possible shift of lists\n",
    "def shifted_lists(l):\n",
    "    shifted_lists = []\n",
    "    for j in range(len(l)):\n",
    "        list_constructed = copy.deepcopy(l[j:])\n",
    "        list_constructed.extend(l[:j])\n",
    "        list_constructed.append(list_constructed[0])\n",
    "        shifted_lists.append(list_constructed)\n",
    "    return shifted_lists\n",
    "\n",
    "# checks if history hist contains circle c\n",
    "def contains(hist, c):\n",
    "    n = len(c)+1\n",
    "    max_count = 0\n",
    "    lists = shifted_lists(c)\n",
    "    for helper_list in lists:\n",
    "        count = 0\n",
    "        for i in range(len(hist)-(n-1)):\n",
    "            if hist[i:i+n] == helper_list:\n",
    "                count += 1\n",
    "        max_count = max(max_count, count)\n",
    "    return max_count\n",
    "\n",
    "# returns true if edge (e,v) is on c\n",
    "def is_on(e,v,c):\n",
    "    for i in range(len(c)-1):\n",
    "        if c[i] == e and c[i+1] == v:\n",
    "            return True\n",
    "    if c[-1] == e and c[0] == v:\n",
    "        return True\n",
    "\n",
    "\n",
    "# Presented Unrolling algorithm, Algorithm 1 with online reducing\n",
    "def unroll(G, start, target, k, debug = False):\n",
    "    G_gen = nx.DiGraph()\n",
    "    G_gen.add_node(start, hist = [str(start)])\n",
    "    if 'controllable' in G.nodes[start]:\n",
    "        G_gen.nodes[start][\"controllable\"] = G.nodes[start][\"controllable\"]\n",
    "\n",
    "    cycles = list(nx.simple_cycles(G))\n",
    "\n",
    "    queue = [start]\n",
    "    # start bf-search\n",
    "    while(queue):\n",
    "        s = queue[0]\n",
    "        queue.pop(0)\n",
    "        s_original = str(s).split(\"vv\")[0]\n",
    "        neighbours = list(G[s_original])\n",
    "        for t in neighbours:\n",
    "            t_original = t\n",
    "            local_hist = copy.deepcopy(G_gen.nodes[s][\"hist\"])\n",
    "            local_hist.append(str(t_original))\n",
    "            is_on_cycle = False\n",
    "            can_traverse = False\n",
    "            path = []\n",
    "            circle = []\n",
    "            relevant_cycle = []\n",
    "            for c in cycles:\n",
    "                if is_on(s_original,t_original,c):\n",
    "                    relevant_cycle.append(c)\n",
    "                    \n",
    "            all_smaller = True\n",
    "            for c in relevant_cycle:\n",
    "                if contains(local_hist,c) >= k:\n",
    "                    all_smaller = False\n",
    "            \n",
    "            if not all_smaller:\n",
    "                paths = list(nx.all_simple_paths(G, source=t, target=target))\n",
    "                for p in paths:\n",
    "                    merged_hist = copy.deepcopy(local_hist)\n",
    "                    merged_hist.extend(p[1:]) # 1.st element already added\n",
    "                    can_not_traverse = False\n",
    "                    \n",
    "                    #test if no loop larger than k with path\n",
    "                    for c_loop in relevant_cycle:\n",
    "                        if contains(merged_hist,c_loop) > k : # check that there is path without completing additional cycle\n",
    "                            can_not_traverse = True\n",
    "                    can_traverse = not can_not_traverse\n",
    "            if all_smaller or can_traverse:               \n",
    "                #every node not on cycle can be unqiue (\"merge point\" within unrolled graph)\n",
    "                if relevant_cycle:\n",
    "                    while t in G_gen.nodes:\n",
    "                        if \"vv\" not in t:\n",
    "                            t += \"vv1\"\n",
    "                        else:\n",
    "                            t = t.split(\"vv\")[0]+\"vv\"+str(int(t.split(\"vv\")[-1])+1)\n",
    "                # add node t only to graph if not already treated\n",
    "\n",
    "                if t not in queue:\n",
    "                    queue.append(t)\n",
    "                    G_gen.add_node(t, hist = local_hist)\n",
    "                assert(s in G_gen and t in G_gen)\n",
    "                G_gen.add_edge(s,t)\n",
    "                if('label' in G[s_original][t_original]):\n",
    "                    G_gen[s][t]['label'] = G[s_original][t_original]['label']\n",
    "                if('controllable' in G[s_original][t_original]): # transition systems store controllability in edges\n",
    "                    G_gen[s][t]['controllable'] = G[s_original][t_original]['controllable']\n",
    "                if('controllable' in G.nodes[t_original]): # dfg stores in nodes\n",
    "                    G_gen.nodes[t]['controllable'] = G.nodes[t_original]['controllable']\n",
    "\n",
    "    print(\"Graph was unrolled\")\n",
    "    return G_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0555595",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_unroll = unroll(g, \"start\", [\"finPos\", \"finNeg\"], 1)\n",
    "A = to_agraph(g_unroll)\n",
    "A.layout('dot')\n",
    "if SAVE_ELEMENTS:\n",
    "    A.draw('unrolled.ps')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93488cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method to produce unrolled graph\n",
    "def to_uppaal(g):\n",
    "    f = open(\"unrolled_graph.xml\", \"w+\")\n",
    "    \n",
    "    pos = nx.drawing.nx_agraph.graphviz_layout(g, prog='dot', args='-Grankdir=LR')\n",
    "\n",
    "    f.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>')\n",
    "    f.write(\"<!DOCTYPE nta PUBLIC '-//Uppaal Team//DTD Flat System 1.1//EN' 'http://www.it.uu.se/research/group/darts/uppaal/flat-1_1.dtd'>\")\n",
    "    f.write('<nta>')\n",
    "    f.write('<declaration>')\n",
    "    f.write('int gas = 0;')\n",
    "    f.write('\\n'+'int finalGasMax = 0;')\n",
    "    f.write('\\n'+'int finalGasMin = 10000;')\n",
    "    f.write('\\n'+'clock x;')\n",
    "    f.write('\\n'+'hybrid clock t;')\n",
    "    f.write('\\n'+'int steps;')\n",
    "    f.write('</declaration>')\n",
    "    f.write('<template>')\n",
    "    f.write('<name x=\"5\" y=\"5\">Template</name>')\n",
    "    \n",
    "    # print locations\n",
    "    ids = {}\n",
    "    for s,i in zip(pos, range(len(pos))):\n",
    "        ids[s] = i\n",
    "        print_location(f, \"id\"+str(i),pos[s][0],pos[s][1],s)\n",
    "    \n",
    "    f.write('<init ref=\"id'+str(ids['start'])+'\"/>')\n",
    "    for e in g.edges:\n",
    "        final = True if \"finPos\" in e[1] or \"finNeg\" in e[1] else False\n",
    "        print_edge(f, ids[e[0]], ids[e[1]], pos[e[0]], pos[e[1]], g[e[0]][e[1]]['label'], g.nodes[e[1]]['controllable'], final = final)\n",
    "    f.write('</template>')\n",
    "    f.write('<system>')\n",
    "    f.write('Journey = Template();')\n",
    "    f.write('system Journey;')\n",
    "    f.write('</system>')\n",
    "    f.write('</nta>')\n",
    "    f.close()\n",
    "    print(\"All written to\", f.name)\n",
    "\n",
    "def print_location(f, location_id, x, y, name):\n",
    "    f.write('<location id=\"'+location_id+'\" x=\"'+str(int(x))+'\" y=\"'+str(int(y))+'\">')\n",
    "    f.write('<name x=\"'+str(int(x))+'\" y=\"'+str(int(y))+'\">'+str(name).replace(\":\", \"\").replace(\" \",\"\").replace(\".\", \"\").replace(\",\", \"\").replace(\"-\",\"\")+'</name>')\n",
    "    f.write('<label kind=\"invariant\" x=\"'+str(int(x))+'\" y=\"'+str(int(y))+'\">')\n",
    "    if \"finPos\" not in name and \"finNeg\" not in name:\n",
    "        f.write('x &lt;= ' + str(2))\n",
    "    else:\n",
    "        f.write(\"t'==0\")\n",
    "    f.write('</label>')\n",
    "    f.write('</location>')\n",
    "\n",
    "def print_edge(f, s, t, pos_s, pos_t, weight, controllable, final = False):\n",
    "    x = (pos_s[0]+pos_t[0])/2\n",
    "    y = (pos_s[1]+pos_t[1])/2\n",
    "    if controllable:\n",
    "        f.write('<transition action = \"\">')\n",
    "    else:\n",
    "        f.write('<transition controllable=\"false\" action = \"\">')\n",
    "    f.write('<source ref=\"id'+str(s)+'\"/>')\n",
    "    f.write('<target ref=\"id'+str(t)+'\"/>')\n",
    "    \n",
    "    f.write('<label kind=\"assignment\" x=\"'+str(int(x))+'\" y=\"'+str(int(y))+'\">')\n",
    "    if final:\n",
    "        f.write('finalGasMax = gas +'+str(int(round(weight))))\n",
    "        f.write(',\\n'+'finalGasMin = gas +'+str(int(round(weight))))\n",
    "        f.write(',\\n'+ 'gas = gas + '+str(int(round(weight))))\n",
    "    else:\n",
    "        f.write('gas = gas + '+str(int(round(weight))))\n",
    "    \n",
    "    f.write(',\\n'+ 'steps += 1')\n",
    "    f.write(',\\n'+ 'x = 0')\n",
    "    \n",
    "    f.write('</label>')\n",
    "    \n",
    "    f.write('</transition>')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016b509",
   "metadata": {},
   "outputs": [],
   "source": [
    "if SAVE_ELEMENTS:\n",
    "    to_uppaal(g_unroll)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bdcd8044",
   "metadata": {},
   "source": [
    "##  UPPAAL\n",
    "This generated model can then by model checked with UPPAAL."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "46d6bb06",
   "metadata": {},
   "source": [
    "# Generate Simulation Plot\n",
    "Generates comparison plot between GoPos and GoPosFast, Figure 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5151680",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(path):\n",
    "    simulations = []\n",
    "    lines = []\n",
    "    with open(path) as file:\n",
    "        lines = file.readlines()\n",
    "        lines = [line.rstrip() for line in lines]\n",
    "    lines = [line for line in lines if \"##\" not in line]\n",
    "    lines.pop(0)\n",
    "    x = []\n",
    "    y = []\n",
    "    current_x = []\n",
    "    current_y = []\n",
    "    current_simulation = []\n",
    "    for line in lines:\n",
    "        if \"#\" in line:\n",
    "            current_x.append(30)\n",
    "            current_y.append(current_y[-1])\n",
    "            x.append(current_x)\n",
    "            y.append(current_y)\n",
    "            current_x = []\n",
    "            current_y = []\n",
    "        else:\n",
    "            current_x.append(float(line.split(\",\")[0]))\n",
    "            current_y.append(float(line.split(\",\")[1]))\n",
    "    return x,y\n",
    "\n",
    "x,y = read_csv(\"gopos.csv\")\n",
    "x_fast, y_fast = read_csv(\"goposfast.csv\")\n",
    "plt.rcParams[\"figure.autolayout\"] = True\n",
    "for i in range(len(x)):\n",
    "    if i == len(x)-1:\n",
    "        plt.plot(x[i],y[i], c = \"r\", linewidth = 1, label = \"GoPos\")\n",
    "    else:\n",
    "        plt.plot(x[i],y[i], c = \"r\", linewidth = 1)\n",
    "for i in range(len(x_fast)):\n",
    "    if i == len(x_fast)-1:\n",
    "        plt.plot(x_fast[i],y_fast[i], c = \"b\", linewidth = 1, label = \"GoPosFast\")\n",
    "    else:\n",
    "        plt.plot(x_fast[i],y_fast[i], c = \"b\", linewidth = 1)\n",
    "plt.legend()\n",
    "plt.savefig(\"simulation.png\")\n",
    "plt.xlabel(\"Time (t)\",  fontsize=18)\n",
    "plt.ylabel(\"Gas\",  fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "176d61de",
   "metadata": {},
   "source": [
    "## Write transition system to UPPAAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af80661c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concats the trace to a multiset-history\n",
    "def ms(trace):\n",
    "    multiset = {}\n",
    "    for pos in trace:\n",
    "        if pos not in multiset:\n",
    "            multiset[pos] = 1\n",
    "        else:\n",
    "            multiset[pos] += 1\n",
    "    return json.dumps(multiset, sort_keys=True).encode().decode(\"utf-8\") # use json encodings for multisets\n",
    "\n",
    "# Computes the sequence-history of the given trace\n",
    "def sequence(trace): \n",
    "    hist = str(trace[0])\n",
    "    for pos in trace[1:]:\n",
    "        hist += \" - \" + str(pos) # construct history\n",
    "    return hist\n",
    "\n",
    "# Function to compute a transition system, given a pre-processed log\n",
    "def transition_system(log, history, abstraction):\n",
    "    edges = []\n",
    "    edge_counter = {}\n",
    "    controll = {}\n",
    "    action = {}\n",
    "    edge_mapping = {}\n",
    "    for trace_index in range(len(log)):\n",
    "        trace = log[trace_index]\n",
    "        s = \"start\"\n",
    "        assert(trace[0]==\"start\")\n",
    "        for pos_index in range(1,len(trace)):\n",
    "            pos = trace[pos_index]\n",
    "            activity = pos\n",
    "            #t = ms(trace[max(0,pos_index-history+1):pos_index+1])\n",
    "            t = abstraction(trace[max(0,pos_index-history+1):pos_index+1])\n",
    "            e = (s,t)\n",
    "            action[e] = activity\n",
    "            if e not in edges:\n",
    "                edges.append(e)\n",
    "                edge_counter[e] = 1\n",
    "                edge_mapping[e] = [trace_index]\n",
    "            else:\n",
    "                if trace_index not in edge_mapping[e] or True:\n",
    "                    # if transition observed twice in one run, dont count twice in computation\n",
    "                    edge_counter[e] = edge_counter[e]+1\n",
    "                    edge_mapping[e].append(trace_index)\n",
    "            s = t\n",
    "    g = nx.DiGraph()\n",
    "    for e in edges:\n",
    "        g.add_edge(e[0], e[1])\n",
    "    to_remove = [] # to remove selve-loops\n",
    "    for e in g.edges:\n",
    "        if e[0] == e[1]:\n",
    "            to_remove.append(e)\n",
    "        # set properties\n",
    "        g[e[0]][e[1]]['action'] = action[e]\n",
    "\n",
    "    for e in to_remove:\n",
    "        if e in g.edges():\n",
    "            g.remove_edge(e[0],e[1])\n",
    "    \n",
    "    return g, edge_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07175b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transition system needs different write-to-xml methods\n",
    "\n",
    "# construction of uppaal model (write model into upaal file)\n",
    "def to_uppaal_transition(g, name, layout = \"sfdp\", debug = False):\n",
    "    f = open(name, \"w+\")\n",
    "    \n",
    "    pos = nx.drawing.nx_agraph.graphviz_layout(g, prog=layout, args='-Grankdir=LR')\n",
    "\n",
    "    f.write('<?xml version=\"1.0\" encoding=\"utf-8\"?>')\n",
    "    f.write(\"<!DOCTYPE nta PUBLIC '-//Uppaal Team//DTD Flat System 1.1//EN' 'http://www.it.uu.se/research/group/darts/uppaal/flat-1_1.dtd'>\")\n",
    "    f.write('<nta>')\n",
    "    f.write('<declaration>')\n",
    "    f.write('int gas = 0;')\n",
    "    f.write('\\n'+'clock x;')\n",
    "    f.write('\\n'+'hybrid clock t;')\n",
    "    f.write('\\n'+'int steps;')\n",
    "    f.write('\\n'+'bool reached_positive = false;')\n",
    "    f.write('\\n'+'bool reached_negative = false;')\n",
    "    f.write('\\n'+'bool phase0 = true;')\n",
    "    f.write('\\n'+'bool phase1 = false;')\n",
    "    f.write('\\n'+'bool phase2 = false;')\n",
    "    f.write('\\n'+'int final_gas = -1;')\n",
    "    f.write('</declaration>')\n",
    "    f.write('<template>')\n",
    "    f.write('<name x=\"5\" y=\"5\">Template</name>')\n",
    "    \n",
    "    # print locations\n",
    "    ids = {}\n",
    "    for s,i in zip(pos, range(len(pos))):\n",
    "        ids[s] = i\n",
    "        print_location_transition(f, \"id\"+str(i),pos[s][0],pos[s][1],s)\n",
    "        f.write('\\n')\n",
    "                    \n",
    "    f.write('<init ref=\"id'+str(ids['start'])+'\"/>')\n",
    "    \n",
    "    for e in g.edges:\n",
    "        assert(\"label\" in g[e[0]][e[1]] and \"controllable\" in g[e[0]][e[1]])\n",
    "        print_edge_transition(f, ids[e[0]], ids[e[1]], pos[e[0]], pos[e[1]], g[e[0]][e[1]]['label'], g[e[0]][e[1]]['controllable'], e, g)\n",
    "\n",
    "    f.write('</template>')\n",
    "    f.write('<system>')\n",
    "    f.write('Journey = Template();')\n",
    "    f.write('system Journey;')\n",
    "    f.write('</system>')\n",
    "    f.write('</nta>')\n",
    "    f.close()\n",
    "    if debug:\n",
    "        print(\"all written to\", f.name)\n",
    "\n",
    "def print_location_transition(f, location_id, x, y, name):\n",
    "    name = str(name)\n",
    "    name = name.replace('\"', '-')\n",
    "    name = name.replace('{', '')\n",
    "    name = name.replace('}', '')\n",
    "    name = name.replace(\"'\", '-')\n",
    "    name = name.replace(\"_\", '')\n",
    "    name = name.replace(\"(\", '')\n",
    "    name = name.replace(\")\", '')\n",
    "    f.write('<location id=\"'+location_id+'\" x=\"'+str(int(x))+'\" y=\"'+str(int(y))+'\">')\n",
    "    f.write('<name x=\"'+str(int(x))+'\" y=\"'+str(int(y)+20)+'\">'+str(name).replace(\":\", \"\").replace(\" \",\"\").replace(\".\", \"\").replace(\",\", \"\").replace(\"-\",\"\")+'</name>')\n",
    "    f.write('<label kind=\"invariant\" x=\"'+str(int(x))+'\" y=\"'+str(int(y)-30)+'\">')\n",
    "    if \"finPos\" not in name and \"finNeg\" not in name and \"outOfGas\" not in name:\n",
    "        f.write('x &lt;= ' + str(2))\n",
    "    else:\n",
    "        f.write(\"t'==0\")\n",
    "    f.write('</label>')\n",
    "    f.write('</location>')\n",
    "\n",
    "def print_edge_transition(f, s, t, pos_s, pos_t, w, controllable, e, g, guard = False):  \n",
    "\n",
    "    x = (pos_s[0]+pos_t[0])/2\n",
    "    y = (pos_s[1]+pos_t[1])/2\n",
    "    if controllable:\n",
    "        f.write('<transition action = \"\">')\n",
    "    else:\n",
    "        f.write('<transition controllable=\"false\" action = \"\">')\n",
    "    f.write('<source ref=\"id'+str(s)+'\"/>')\n",
    "    f.write('<target ref=\"id'+str(t)+'\"/>')\n",
    "        \n",
    "    f.write('<label kind=\"assignment\" x=\"'+str(int(x))+'\" y=\"'+str(int(y))+'\">')\n",
    "    f.write(' steps += 1')\n",
    "    f.write(',\\n'+ 'x = 0')\n",
    "    if \"finPos\" in str(e[1]):\n",
    "        f.write(',\\n'+ 'reached_positive = true')\n",
    "        f.write(',\\n'+ 'final_gas = gas +'+str(int(round(w))))\n",
    "    elif \"finNeg\" in str(e[1]):\n",
    "        f.write(',\\n'+ 'reached_negative = true')\n",
    "        f.write(',\\n'+ 'final_gas = gas + '+str(int(round(w))))\n",
    "        \n",
    "    if \"started - Task event: 0\" in e[1]:\n",
    "        f.write(',\\n'+ 'phase0 = false')\n",
    "        f.write(',\\n'+ 'phase1 = true')\n",
    "    if \"waitingForResultApproval\" in e[1]:\n",
    "        f.write(',\\n'+ 'phase1 = false')\n",
    "        f.write(',\\n'+ 'phase2 = true')\n",
    "\n",
    "    f.write(',\\n'+'gas = gas + '+str(int(round(w))))\n",
    "    f.write('</label>')\n",
    "    \n",
    "    f.write('</transition>')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1290ebbe",
   "metadata": {},
   "source": [
    "# Analysing Time Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa7597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort log with start_times\n",
    "\n",
    "# most prominent companies\n",
    "reduced_sorted_times = [t for t in sorted_times if (t[1][1]- t[1][0]).days < MAX_DURATION_JOURNEY]\n",
    "company_list = []\n",
    "for t in reduced_sorted_times:\n",
    "    company_index = company_iterator[companies[t[0]]]\n",
    "    company_list.append(company_index)\n",
    "\n",
    "# generates sliding window log\n",
    "def sliding_window_logs(log, start_times, execution_times, window_size_days = 49, min_size = 30, companies = [], draw_plot = False):\n",
    "    # assert that log, start_times and execution_times have right format\n",
    "    assert(len(log) == len(start_times))\n",
    "    for i in range(len(log)):\n",
    "        assert(len(log[i])==len(execution_times[i]))\n",
    "\n",
    "    merged = [(log, start_time, execution_time) for log, start_time, execution_time in zip (log, start_times, execution_times)]\n",
    "    start_times_sorted = sorted(merged, key=lambda item: item[1])\n",
    "    sorted_log = [s[0] for s in start_times_sorted]\n",
    "    sorted_times = [s[1] for s in start_times_sorted]\n",
    "    sorted_execution_times = [s[2] for s in start_times_sorted]\n",
    "\n",
    "    assert(len(sorted_execution_times) == len(sorted_log))\n",
    "    assert(sorted(start_times) == sorted_times)\n",
    "    assert(len(sorted_times)==len(sorted_execution_times))\n",
    "    for i in range(len(sorted_times)):\n",
    "        assert(sorted_times[i]==sorted_execution_times[i][0])\n",
    "        assert(len(sorted_log[i])==len(sorted_execution_times[i]))\n",
    "    \n",
    "    sliced_logs = []\n",
    "    sliced_companies = []\n",
    "    sliced_execution_times = []\n",
    "    sliced_start = []\n",
    "    sliced_end = []\n",
    "    \n",
    "    latest_time = max(sorted_times)\n",
    "\n",
    "    for current_start in (min(sorted_times) + timedelta(days = n) for n in range((max(sorted_times)-min(sorted_times)).days+2)): # iterate over all days\n",
    "        window_start = datetime.datetime(current_start.year, current_start.month, current_start.day, 0, 0, 0)\n",
    "        window_end = datetime.datetime(current_start.year, current_start.month, current_start.day, 0, 0, 0)+timedelta(days = window_size_days)\n",
    "\n",
    "        # assure minimal window size\n",
    "        if (latest_time - current_start).days <= min_size:\n",
    "            continue\n",
    "        current_log = []\n",
    "        current_companies = []\n",
    "        current_execution_times = []\n",
    "        index = -1\n",
    "        # check on all traces and build sliced lists\n",
    "        for trace, start_time, execution_time in zip(sorted_log, sorted_times, sorted_execution_times):\n",
    "            assert(len(trace) == len(execution_time))\n",
    "            index += 1\n",
    "            if start_time >= window_start and start_time < window_end:\n",
    "                current_log.append(trace)\n",
    "                current_execution_times.append(execution_time)\n",
    "                if companies != []:\n",
    "                    current_companies.append(companies[index])\n",
    "\n",
    "        sliced_logs.append(current_log)\n",
    "        sliced_companies.append(current_companies)\n",
    "        sliced_execution_times.append(current_execution_times)\n",
    "        sliced_start.append(window_start)\n",
    "        sliced_end.append(window_end)\n",
    "    \n",
    "    # visualize start-times of \n",
    "    if draw_plot:\n",
    "        plt.plot(range(len(sliced_start)), sliced_start, label = \"start-time\")\n",
    "        plt.plot(range(len(sliced_end)), sliced_end, label = \"end-time\")\n",
    "        plt.title(\"Window size: \"+str(window_size_days)+ \" days\")\n",
    "        plt.xlabel(r'Sub-log $L_i$')\n",
    "        plt.ylabel(\"Time\")\n",
    "        plt.legend()\n",
    "        if SAVE_ELEMENTS:\n",
    "            plt.savefig(\"windows.png\")\n",
    "        plt.show()\n",
    "    if companies == []:\n",
    "        return sliced_logs, sliced_execution_times\n",
    "    else:\n",
    "        return sliced_logs, sliced_companies, sliced_execution_times\n",
    "\n",
    "sliced_logs, sliced_companies, sliced_execution_times = sliding_window_logs(log, start_times, execution_times, min_size = 10, draw_plot = True, window_size_days=49, companies=company_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea3781ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot development of users and fraction of successful users\n",
    "\n",
    "print(\"Number of sliced logs\", len(sliced_logs))\n",
    "\n",
    "plt.plot(range(len(sliced_logs)), [len(l) for l in sliced_logs])\n",
    "plt.title(\"Number of users per window\")\n",
    "plt.xlabel(r'Sub-log $L_i$')\n",
    "plt.ylabel(\"#Users\")\n",
    "if SAVE_ELEMENTS:\n",
    "    plt.savefig(\"#users.png\")\n",
    "plt.show()\n",
    "\n",
    "fractions = []\n",
    "for l in sliced_logs:\n",
    "    pos = [t for t in l if \"finPos\" in t]\n",
    "    neg = [t for t in l if \"finNeg\" in t]\n",
    "    assert(len(l) >0)\n",
    "    fractions.append(len(pos)/len(l))\n",
    "    assert(len(pos)+len(neg) == len(l))\n",
    "plt.plot(range(len(fractions)), fractions)\n",
    "plt.title(\"Fraction of successful users\")\n",
    "plt.xlabel(r'Sub-log $L_i$')\n",
    "plt.ylabel(\"Fractions Successful Users\")\n",
    "if SAVE_ELEMENTS:\n",
    "    plt.savefig(\"fractions.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a646ab26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare dfg construction with sequence construction\n",
    "def analyse_models(sliced_logs):\n",
    "    loops = []\n",
    "    for l in sliced_logs:\n",
    "        help_g = build_dfg(l, 3)\n",
    "        loops.append(len(list(nx.simple_cycles(help_g))))\n",
    "    plt.title(\"Loops in DFG model per Sub-Log\")\n",
    "    plt.xlabel(r'Sub-log $L_i$')\n",
    "    plt.ylabel(\"Loops\")\n",
    "    plt.plot(range(len(loops)), loops)\n",
    "    plt.show()\n",
    "\n",
    "    loops = []\n",
    "    for l in sliced_logs:\n",
    "        help_g, edge_mapping = transition_system(l, 2, sequence)        \n",
    "        loops.append(len(list(nx.simple_cycles(help_g))))\n",
    "    plt.title(\"Loops in 2-history Sequence model per Sub-Log\")\n",
    "    plt.xlabel(r'Sub-log $L_i$')\n",
    "    plt.ylabel(\"Loops\")\n",
    "    plt.plot(range(len(loops)), loops)\n",
    "    plt.show()\n",
    "\n",
    "analyse_models(sliced_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7119eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_results(result_dict):\n",
    "    colors = result_dict[\"colors\"]\n",
    "    fig, axs = plt.subplots(4, 2, figsize=(15, 15))\n",
    "    axs[0,0].hist(result_dict[\"loops\"], 20)\n",
    "    axs[0,0].set_title(\"Loop Histogram\")\n",
    "\n",
    "    axs[0,1].scatter(range(len(result_dict[\"loops\"])), result_dict[\"loops\"], s = 2)\n",
    "    axs[0,1].set_title(\"Loops\")\n",
    "\n",
    "    axs[1,0].scatter(range(len(result_dict[\"distances\"])), result_dict[\"distances\"], s = 2)\n",
    "    axs[1,0].set_title(\"Distances\")\n",
    "\n",
    "    axs[1,1].scatter(range(len(result_dict[\"distances_previous\"])), result_dict[\"distances_previous\"], s = 2)\n",
    "    axs[1,1].set_title(\"Pairwise - Distances\")\n",
    "    \n",
    "    axs[2,0].plot(range(len(result_dict[\"fractions\"])), result_dict[\"fractions\"])\n",
    "    axs[2,0].set_title(\"Fractions\")\n",
    "\n",
    "    axs[2,1].plot(range(len(result_dict[\"sliced_logs\"])), [len(l) for l in result_dict[\"sliced_logs\"]])\n",
    "    axs[2,1].set_title(\"#Users\")\n",
    "\n",
    "    axs[3,0].scatter(range(len(result_dict[\"negative_edges\"])), [len(e) for e in result_dict[\"negative_edges\"]], s = 10)\n",
    "    axs[3,0].set_title(\"Number negative edges\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def plot_mc_results(mc_results, colors):\n",
    "    lables = [r'$E(steps)$', \"min Gas\", \"max finalGas\"]\n",
    "    for i in range(6):\n",
    "        plt.plot(range(len(mc_results)), [r[i] for r in mc_results])\n",
    "        if \"min\" in lables[i%3]:\n",
    "            x = [ind for ind in range(len(mc_results)) if mc_results[ind][i] == 1]\n",
    "        else:\n",
    "            x = [ind for ind in range(len(mc_results)) if mc_results[ind][i] == -1]\n",
    "        plt.scatter(x, np.array([r[i] for r in mc_results])[x], marker =\"x\", c = \"red\")\n",
    "        plt.axvspan(0, 120, facecolor='green', alpha=0.2)\n",
    "        plt.axvspan(270, 320, facecolor='red', alpha=0.2)\n",
    "        plt.axvspan(390, 450, facecolor='red', alpha=0.2)\n",
    "        plt.axvspan(550, 585, facecolor='red', alpha=0.2)\n",
    "        plt.xlabel(r'Sub-log $L_i$', size = 20)\n",
    "        plt.ylabel(lables[i%3], size = 20)\n",
    "        if SAVE_ELEMENTS:\n",
    "            plt.savefig(\"mc_\"+str(i)+\".png\")\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f880e",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_old_history, h = transition_system(log_single, 2, sequence)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8ad986a4",
   "metadata": {},
   "source": [
    "## Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c2c3d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_analysis(sliced_logs, abstraction_length = 1, edge_threshold = 0, compute_distance = True, distance_time = 10, draw_intermediate = False):\n",
    "    result_dict = {\n",
    "        \"loops\" : [],\n",
    "        \"mc_results\" : [],\n",
    "        \"distances\" : [],\n",
    "        \"distances_previous\" : [0],\n",
    "        \"colors\" : [],\n",
    "        \"fractions\" : [],\n",
    "        \"edge_thresholds\" : [],\n",
    "        \"negative_edges\" : [],\n",
    "        \"sliced_logs\" : sliced_logs\n",
    "    }\n",
    "\n",
    "    omitted_counter = 0\n",
    "    successfully_computed = 0\n",
    "\n",
    "    for l in sliced_logs:\n",
    "        # add default values if sub-log is empty (might occur when investigating companies)\n",
    "        if len(l) == 0:\n",
    "            result_dict[\"loops\"].append(-1)\n",
    "            result_dict[\"mc_results\"].append([-10,-10,-10,-10,-10,-10])\n",
    "            result_dict[\"distances\"].append(-1)\n",
    "            result_dict[\"distances_previous\"].append(-1)\n",
    "            result_dict[\"colors\"].append(\"violet\")\n",
    "            result_dict[\"fractions\"].append(-1)\n",
    "            continue\n",
    "        result_dict[\"fractions\"].append(len([t for t in l if \"finPos\" in t])/len(l))\n",
    "            \n",
    "\n",
    "        if compute_distance:\n",
    "            if len(result_dict[\"distances\"]) > 0:\n",
    "                h1, h2 = transition_system(l, abstraction_length, sequence)\n",
    "                result_dict[\"distances_previous\"].append(nx.graph_edit_distance(h1, help_g, timeout = distance_time))\n",
    "\n",
    "        # build model\n",
    "        help_g, edge_mapping = transition_system(l, abstraction_length, sequence)\n",
    "        extend_graph_with_actors(help_g,actors, transition_system=True)\n",
    "        edge_to_remove = []\n",
    "        for e in help_g.edges:\n",
    "            if len(edge_mapping[e]) <= edge_threshold:\n",
    "                edge_to_remove.append(e)\n",
    "        help_g.remove_edges_from(edge_to_remove)\n",
    "        help_g.remove_nodes_from(list(nx.isolates(help_g)))\n",
    "\n",
    "        loop_number = len(list(nx.simple_cycles(help_g)))\n",
    "\n",
    "        if compute_distance:\n",
    "            print(\"compute distance\")\n",
    "            result_dict[\"distances\"].append(nx.graph_edit_distance(g_old_history, help_g, timeout = distance_time))\n",
    "\n",
    "        result_dict[\"loops\"].append(loop_number)\n",
    "        result_dict[\"edge_thresholds\"].append(edge_threshold)\n",
    "\n",
    "        assert(not nx.is_empty(help_g))\n",
    "        assert(nx.is_weakly_connected(help_g))\n",
    "        if loop_number > 6:\n",
    "            #assume that all models have sufficiently little loops\n",
    "            assert(False)\n",
    "        \n",
    "        #compute cost for model\n",
    "        help_edge_cost = compute_edge_cost(help_g, l, edge_mapping)\n",
    "        help_g = annotate_graph(help_g, help_edge_cost)\n",
    "\n",
    "        negative_edges = [e for e in help_edge_cost if help_edge_cost[e] < 0]\n",
    "        result_dict[\"negative_edges\"].append(negative_edges)\n",
    "        \n",
    "        if draw_intermediate:\n",
    "            draw_dfg(help_g, \"graph_loops.ps\")\n",
    "        \n",
    "        assert(\"start\" in help_g.nodes)\n",
    "\n",
    "        target = [s for s in help_g.nodes if \"finPos\" in s or \"finNeg\" in s]\n",
    "        help_g_unroll = unroll(help_g, \"start\", target, 1)\n",
    "        \n",
    "        if draw_intermediate:\n",
    "            draw_dfg(help_g_unroll, \"graph_loops_unrolled.ps\")\n",
    "        \n",
    "        # write to uppaal\n",
    "        to_uppaal_transition(help_g_unroll, \"unrolled_graph_transition.xml\", layout = \"dot\")\n",
    "        # run queries\n",
    "        out = subprocess.Popen([VERIFYTA_PATH, \"unrolled_graph_transition.xml\", \"unrolled_graph_transition.q\"], stdout=subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "        out.wait()\n",
    "        # parse output\n",
    "        results, err = out.communicate()\n",
    "        results = results.decode(\"utf-8\") \n",
    "        err = str(err.decode(\"utf-8\"))\n",
    "        if err != \"\":\n",
    "            results = [-1,1,-1,-1,1,-1]\n",
    "        else:\n",
    "            results = results.split(\"\\n\")\n",
    "            results = [results[i+1] for i in range(len(results)-1) if \"Formula\" in results[i] and \"E\" in results[i+1]]\n",
    "            results = [r.replace(\"\", \"\") for r in results]\n",
    "            results = [float(r.split(\"\")[0].split(\"runs)\")[1].split(\"=\")[1].strip()) for r in results]\n",
    "            successfully_computed += 1\n",
    "        assert(len(results) == 6)\n",
    "\n",
    "        result_dict[\"mc_results\"].append(results)\n",
    "        \n",
    "        result_dict[\"colors\"].append(\"b\" if results == [-1,1,-1,-1,1,-1] else \"g\")\n",
    "        print(\"Progress\", len(result_dict[\"loops\"]), \"/\", len(sliced_logs))\n",
    "\n",
    "    print(\"Successfully computed\", successfully_computed)\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60eaa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_distances_pairwise(i):\n",
    "    distance_time = 10\n",
    "    if i == 0:\n",
    "        return 0\n",
    "    c1, c2 = transition_system(sliced_logs[i], 2, sequence)\n",
    "    o1, o2 = transition_system(sliced_logs[i-1], 2, sequence)\n",
    "    return nx.graph_edit_distance(c1, o1, timeout = distance_time)\n",
    "\n",
    "def compute_distances(i):\n",
    "    distance_time = 10\n",
    "    c1, c2 = transition_system(sliced_logs[i], 2, sequence)\n",
    "    return nx.graph_edit_distance(g_old_history, c1, timeout = distance_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6335f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "if COMPUTE_SEQUENCE:\n",
    "    result_dict_sequence = time_analysis(sliced_logs, abstraction_length = 2, edge_threshold = 0, compute_distance=False)\n",
    "    if COMPUTE_SEQUENCE_DISTANCE:\n",
    "        with Pool(N_PROCESSORS) as p:\n",
    "            result_dict_sequence['distances_previous'] = p.map(compute_distances_pairwise, range(len(sliced_logs)))\n",
    "            result_dict_sequence['distances'] = p.map(compute_distances, range(len(sliced_logs)))\n",
    "    if SAVE_ELEMENTS:\n",
    "        with open('result_dict_sequence.pkl', 'wb') as f:\n",
    "            pickle.dump(result_dict_sequence, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca27cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not COMPUTE_SEQUENCE:\n",
    "    with open('result_dict_sequence.pkl', 'rb') as f:\n",
    "        loaded_dict = pickle.load(f)\n",
    "    result_dict_sequence = loaded_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53862124",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(result_dict_sequence)\n",
    "plot_mc_results(result_dict_sequence[\"mc_results\"], result_dict_sequence[\"colors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8fcb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_range(L):\n",
    "    for i, j in itertools.groupby(enumerate(L), lambda x: x[1] - x[0]):\n",
    "        j = list(j)\n",
    "        start = j[0][1]\n",
    "        length = len(j)\n",
    "\n",
    "        if length == 1:\n",
    "            yield start\n",
    "        else:\n",
    "            yield (start, start+length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b53cf06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse correlation between min_gas and max_final_gas\n",
    "\n",
    "# Strategy goPos\n",
    "min_gas = [r[1] for r in result_dict_sequence[\"mc_results\"]]\n",
    "max_final_gas = [r[2] for r in result_dict_sequence[\"mc_results\"]]\n",
    "\n",
    "min_gas_indices = [i for i in range(len(min_gas)) if min_gas[i]<=-10]\n",
    "print(\"range min gas\", len(min_gas_indices), list(detect_range(min_gas_indices)))\n",
    "\n",
    "max_final_gas_indices = [i for i in range(len(max_final_gas)) if max_final_gas[i]>=250]\n",
    "print(\"range max final\", len(min_gas_indices), list(detect_range(max_final_gas_indices)))\n",
    "\n",
    "colors = [\"r\" if i in min_gas_indices else \"g\" if i in max_final_gas_indices else \"b\" for i in range(len(min_gas))]\n",
    "\n",
    "plt.scatter(max_final_gas, min_gas, s = 2,  c = colors)\n",
    "plt.xlabel(\"max_final_gas\")\n",
    "plt.ylabel(\"min_gas\")\n",
    "plt.title(\"goPos\")\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].scatter(range(len(result_dict_sequence[\"fractions\"])), result_dict_sequence[\"fractions\"], s = 2, c = colors)\n",
    "axs[0].set_title(\"Fractions\")\n",
    "axs[1].scatter(range(len(result_dict_sequence[\"sliced_logs\"])), [len(l) for l in result_dict_sequence[\"sliced_logs\"]], s = 2, c = colors)\n",
    "axs[1].set_title(\"Users\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6f1b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strategy goPosFast\n",
    "min_gas = [r[4] for r in result_dict_sequence[\"mc_results\"]]\n",
    "max_final_gas = [r[5] for r in result_dict_sequence[\"mc_results\"]]\n",
    "\n",
    "min_gas_indices = [i for i in range(len(min_gas)) if min_gas[i]<=-10]\n",
    "print(\"range min gas\", len(min_gas_indices), list(detect_range(min_gas_indices)))\n",
    "\n",
    "max_final_gas_indices = [i for i in range(len(max_final_gas)) if max_final_gas[i]>=250]\n",
    "print(\"range max final\", len(min_gas_indices), list(detect_range(max_final_gas_indices)))\n",
    "\n",
    "colors = [\"r\" if i in min_gas_indices else \"g\" if i in max_final_gas_indices else \"b\" for i in range(len(min_gas))]\n",
    "\n",
    "plt.scatter(max_final_gas, min_gas, s = 2,  c = colors)\n",
    "plt.xlabel(\"max_final_gas\")\n",
    "plt.ylabel(\"min_gas\")\n",
    "plt.title(\"goPosFast\")\n",
    "plt.show()\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axs[0].scatter(range(len(result_dict_sequence[\"fractions\"])), result_dict_sequence[\"fractions\"], s = 2, c = colors)\n",
    "axs[0].set_title(\"Fractions\")\n",
    "axs[1].scatter(range(len(result_dict_sequence[\"sliced_logs\"])), [len(l) for l in result_dict_sequence[\"sliced_logs\"]], s = 2, c = colors)\n",
    "axs[1].set_title(\"Users\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59de9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyse models without MC\n",
    "not_computed_indices = [i for i in range(len(result_dict_sequence['mc_results'])) if result_dict_sequence['mc_results'][i] == [-1,1,-1,-1,1,-1]]\n",
    "\n",
    "uncomputed_ranges = list(detect_range(not_computed_indices))\n",
    "print(\"Not computed are sub-logs\", uncomputed_ranges)\n",
    "\n",
    "plt.plot(range(len(result_dict_sequence['sliced_logs'])), [len(l) for l in result_dict_sequence[\"sliced_logs\"]])\n",
    "plt.scatter(not_computed_indices, [[len(l) for l in result_dict_sequence[\"sliced_logs\"]][i] for i in not_computed_indices], c = \"r\", marker = \"x\")\n",
    "plt.xlabel(r'Sub-log $L_i$', size = 20)\n",
    "plt.ylabel(\"Users\", size = 20)\n",
    "if SAVE_ELEMENTS:    \n",
    "    plt.savefig(\"no_mc.png\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(range(len(result_dict_sequence['fractions'])), result_dict_sequence[\"fractions\"])\n",
    "plt.scatter(not_computed_indices, [result_dict_sequence[\"fractions\"][i] for i in not_computed_indices], c = \"r\")\n",
    "plt.title(\"Fractions\")\n",
    "plt.xlabel(r'Sub-log $L_i$')\n",
    "plt.ylabel(\"Fractions\")\n",
    "if SAVE_ELEMENTS:\n",
    "    plt.savefig(\"no_mc_fractions.png\")\n",
    "plt.show()\n",
    "\n",
    "count = 0\n",
    "for i in range(len(sorted_times)):\n",
    "    t = sorted_times[i]\n",
    "    plt.plot([t[1][0],t[1][1]], [count, count], c=\"red\" if i in not_computed_indices else \"b\")\n",
    "    count += 1\n",
    "plt.title(\"Duration of journeys by cancelled\")\n",
    "plt.xlabel(r'Sub-log $L_i$')\n",
    "plt.ylabel(\"Durations\")\n",
    "plt.show()\n",
    "\n",
    "# Search for logs with trace where \"Task event: 1\" is followed by \"vpcAssignInstance\" (error reason)\n",
    "is_contained = []\n",
    "for index in range(len(result_dict_sequence[\"sliced_logs\"])):\n",
    "    l = result_dict_sequence[\"sliced_logs\"][index]\n",
    "    contained = \"False\"\n",
    "    for trace in l:\n",
    "        for pos in range(len(trace)-1):\n",
    "            if trace[pos] == \"Task event: 1\" and trace[pos+1] == \"vpcAssignInstance\":\n",
    "                contained = \"True\"\n",
    "    is_contained.append(contained)\n",
    "\n",
    "print(\"Task event: 1 is followed by vpcAssignInstance\", list(detect_range([i for i in range(len(is_contained)) if is_contained[i] == \"True\"])))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a1bdac5f",
   "metadata": {},
   "source": [
    "## Analyse negative edges\n",
    "We investiagte the phases in which gas minima occur by extending the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8233e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def negative_edge_occurences(logs):\n",
    "    phases = []\n",
    "    \n",
    "    for l in logs:\n",
    "        if len(l) == 0:\n",
    "            phases.append(\"none\")\n",
    "            continue\n",
    "\n",
    "        # build unrolled process model\n",
    "        help_g, edge_mapping = transition_system(l, 2, sequence)\n",
    "        extend_graph_with_actors(help_g,actors, transition_system=True)\n",
    "        help_edge_cost = compute_edge_cost(help_g, l, edge_mapping)\n",
    "        help_g = annotate_graph(help_g, help_edge_cost)\n",
    "\n",
    "        target = [s for s in help_g.nodes if \"finPos\" in s or \"finNeg\" in s]\n",
    "        help_g_unroll = unroll(help_g, \"start\", target, 1)\n",
    "\n",
    "        to_uppaal_transition(help_g_unroll, \"unrolled_graph_transition.xml\", layout = \"dot\")\n",
    "\n",
    "        # find min\n",
    "        out = subprocess.Popen([VERIFYTA_PATH, \"unrolled_graph_transition.xml\", \"min_gas_query.q\", \"-s\"], stdout=subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "        out.wait()\n",
    "        results, err = out.communicate()\n",
    "        results = results.decode(\"utf-8\")\n",
    "        err = err.decode(\"utf-8\") \n",
    "        if err != \"\":\n",
    "            phases.append(\"none\")\n",
    "        else:\n",
    "            results = results.split(\"\\n\")\n",
    "            results = [i for i in results if \"mean=\" in i]\n",
    "            assert(len(results)== 1)\n",
    "            min_gas = int(float(results[0].split(\"mean=\")[1].split(\" \")[0]))\n",
    "\n",
    "            # start with mean values and go down until can only be achieved in one phase\n",
    "            results = [True, True, True, True, True]\n",
    "            while sum(results) > 3: # first two queries have to be true and then one for the phases\n",
    "                with open(\"auto_sim.q\", 'w+') as outfile:\n",
    "                    outfile.write(\"A[] phase0 + phase1 + phase2 == 1 \\n\") #check that file is correct\n",
    "                    outfile.write(\"strategy goPos = control: A<> reached_positive\\n\")\n",
    "                    outfile.write(\"control: A<> gas <= \" + str(min_gas) + \" && phase0 under goPos \\n\")\n",
    "                    outfile.write(\"control: A<> gas <= \" + str(min_gas) + \" && phase1 under goPos \\n\")\n",
    "                    outfile.write(\"control: A<> gas <= \" + str(min_gas) + \" && phase2 under goPos \\n\")\n",
    "                out = subprocess.Popen([VERIFYTA_PATH, \"-s\", \"unrolled_graph_transition.xml\", \"auto_sim.q\"], stdout=subprocess.PIPE, stderr = subprocess.PIPE)\n",
    "                out.wait()\n",
    "                results, err = out.communicate()\n",
    "                results = results.decode(\"utf-8\") \n",
    "                err = err.decode(\"utf-8\") \n",
    "                if err != \"\":\n",
    "                    print(err)\n",
    "                    phases.append(\"none\")\n",
    "                else:\n",
    "                    results = results.split(\"\\n\")\n",
    "                    results = [i for i in results if \"-- Formula is\" in i]\n",
    "                    results = [False if \"NOT\" in i else True for i in results]\n",
    "                    assert(results[0])\n",
    "                min_gas -= 1\n",
    "            assert(sum(results)<=3)\n",
    "            assert(results[0])\n",
    "            if sum(results) == 3:\n",
    "                if results[2]:\n",
    "                    phases.append(\"start\")\n",
    "                elif results[3]:\n",
    "                    phases.append(\"work\")\n",
    "                else:\n",
    "                    phases.append(\"submit\")\n",
    "            else:\n",
    "                phases.append(\"not found\")\n",
    "    return phases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce59283",
   "metadata": {},
   "outputs": [],
   "source": [
    "phases = negative_edge_occurences(sliced_logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c107a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_markers = [\"<\" if c == \"start\" else \"o\" if c == \"work\" else \">\" if c == \"submit\" else \".\" for c in phases]\n",
    "\n",
    "x = np.array(range(len(phases)))\n",
    "\n",
    "for m,h in zip([\"<\",\"o\",\">\", \".\"], [1,2,3,-1]):\n",
    "    x_index = [i for i in x if phase_markers[i] == m]\n",
    "    plt.scatter(x_index, [h for i in range(len(x_index))], marker = m, label=m)\n",
    "plt.legend()\n",
    "plt.title(\"Phases for all companies\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "26bc351d",
   "metadata": {},
   "source": [
    "# Analyse by company\n",
    "We analyse developments of the largest companies and investigate how Greps can improve individual interactions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799b48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most prominent companies and their users\n",
    "reduced_sorted_times = [t for t in sorted_times if (t[1][1]- t[1][0]).days < MAX_DURATION_JOURNEY]\n",
    "company_counts = {}\n",
    "for t in reduced_sorted_times:\n",
    "    company_index = company_iterator[companies[t[0]]]\n",
    "    if company_index not in company_counts:\n",
    "        company_counts[company_index] = 1\n",
    "    else:\n",
    "        company_counts[company_index] += 1\n",
    "for c in company_counts:\n",
    "    if company_counts[c] >= 10:\n",
    "        print(c, company_counts[c], company_counts[c]/sum([company_counts[h] for h in company_counts]))\n",
    "\n",
    "print(\"users total\", len(reduced_sorted_times))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694d1a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 3 companies\n",
    "count = 0\n",
    "\n",
    "for t in reduced_sorted_times:\n",
    "    # 3 companies represent 80% of users\n",
    "    company_it = company_iterator[companies[t[0]]]\n",
    "    if company_it == 4:\n",
    "        color = \"red\"\n",
    "    elif company_it == 6:\n",
    "        color = \"blue\"\n",
    "    elif company_it == 8:\n",
    "        color = \"green\"\n",
    "    else:\n",
    "        color = \"white\"\n",
    "    plt.plot([t[1][0],t[1][1]], [count, count], c=color)\n",
    "    count += 1\n",
    "plt.title(\"Duration of journeys, colored by top 3 companies\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9de43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the companiy specific sliding-window logs\n",
    "def filter_by_company(sliced_logs, sliced_companies, company):\n",
    "    filtered_logs = []\n",
    "    for l, companies in zip(sliced_logs, sliced_companies):\n",
    "        current_log = [l[i] for i in range(len(l)) if companies[i] == company]\n",
    "        filtered_logs.append(current_log)\n",
    "    return filtered_logs\n",
    "\n",
    "sliced_log_8 = filter_by_company(sliced_logs, sliced_companies, 8)\n",
    "sliced_log_6 = filter_by_company(sliced_logs, sliced_companies, 6)\n",
    "sliced_log_4 = filter_by_company(sliced_logs, sliced_companies, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa2f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot general developments for top 3 companies\n",
    "plt.plot(range(len(sliced_log_8)),[len(sliced_log_8[i])/len(sliced_logs[i]) for i in range(len(sliced_logs))], label = r'$c_1$')\n",
    "plt.plot(range(len(sliced_log_6)), [len(sliced_log_6[i])/len(sliced_logs[i]) for i in range(len(sliced_logs))], label = r'$c_2$')\n",
    "plt.plot(range(len(sliced_log_4)), [len(sliced_log_4[i])/len(sliced_logs[i]) for i in range(len(sliced_logs))], label = r'$c_3$')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "d4 = [len(sliced_log_4[i])/len(sliced_logs[i]) for i in range(len(sliced_logs))]\n",
    "d6 = [len(sliced_log_6[i])/len(sliced_logs[i]) for i in range(len(sliced_logs))]\n",
    "d8 = [len(sliced_log_8[i])/len(sliced_logs[i]) for i in range(len(sliced_logs))]\n",
    "\n",
    "y = np.vstack([d8, d6, d4])\n",
    "labels = [r'Cust. $c_1$', r'Cust. $c_2$', r'Cust. $c_3$']\n",
    "plt.stackplot(range(len(sliced_logs)), y, labels = labels)\n",
    "plt.xlabel(r'Sub-log $L_i$', size = 20)\n",
    "plt.ylabel(\"User Fraction (stacked)\", size = 20)\n",
    "plt.legend()\n",
    "plt.savefig(\"/home/paul/Documents/User-Journey-Games/windows/company_ratios.png\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fa80fb81",
   "metadata": {},
   "source": [
    "## Time series analysis for top 3 companies\n",
    "We investigate changes over time for the three companies individually. \n",
    "It is from interest if global trends or new local trends can be detected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e748ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_help_4 = time_analysis(sliced_log_4, abstraction_length = 2, edge_threshold = 0, compute_distance=False)\n",
    "plot_results(result_dict_help_4)\n",
    "plot_mc_results(result_dict_help_4[\"mc_results\"], result_dict_help_4[\"colors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c28e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_help_6 = time_analysis(sliced_log_6, abstraction_length = 2, edge_threshold = 0, compute_distance=False)\n",
    "plot_results(result_dict_help_6)\n",
    "plot_mc_results(result_dict_help_6[\"mc_results\"], result_dict_help_6[\"colors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b47dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# investigate phases for company 6\n",
    "phases_6 = negative_edge_occurences(sliced_log_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca77dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot phases and minimum gas\n",
    "phase_markers = [\"<\" if c == \"start\" else \"o\" if c == \"work\" else \">\" if c == \"submit\" else \".\" for c in phases_6]\n",
    "x = np.array(range(len(phases_6)))\n",
    "for m in [\"<\",\"o\",\">\", \".\"]:\n",
    "    x_index = [i for i in x if phase_markers[i] == m]\n",
    "    plt.scatter(x_index, np.array([r[1] for r in result_dict_help_6[\"mc_results\"]])[x_index], marker = m, label = m)\n",
    "\n",
    "plt.legend()\n",
    "if SAVE_ELEMENTS:\n",
    "    plt.savefig(\"steps_6.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b45b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict_help_8 = time_analysis(sliced_log_8, abstraction_length = 2, edge_threshold = 0, compute_distance=False)\n",
    "plot_results(result_dict_help_8)\n",
    "plot_mc_results(result_dict_help_8[\"mc_results\"], result_dict_help_8[\"colors\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f64c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "phases_8 = negative_edge_occurences(sliced_log_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "811b230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_markers = [\"<\" if c == \"start\" else \"o\" if c == \"work\" else \">\" if c == \"submit\" else \".\" for c in phases_8]\n",
    "x = np.array(range(len(phases_8)))\n",
    "for m in [\"<\",\"o\",\">\", \".\"]:\n",
    "    x_index = [i for i in x if phase_markers[i] == m]\n",
    "    plt.scatter(x_index, np.array([r[1] for r in result_dict_help_8[\"mc_results\"]])[x_index], marker = m, label = m)\n",
    "plt.legend()\n",
    "if SAVE_ELEMENTS:\n",
    "    plt.savefig(\"steps_8.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bdaf21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo clean from here\n",
    "result_dicts = [result_dict_help_8,result_dict_help_6,result_dict_help_4]\n",
    "sub_titles = [r'Cust. $c_1$', r'Cust. $c_2$', r'Cust. $c_3$']\n",
    "colors = [\"blue\", \"orange\", \"green\"]\n",
    "\n",
    "fractions = []\n",
    "for l in sliced_logs:\n",
    "    pos = [t for t in l if \"finPos\" in t]\n",
    "    neg = [t for t in l if \"finNeg\" in t]\n",
    "    fractions.append(len(pos)/len(l))\n",
    "    assert(len(pos)+len(neg) == len(l))\n",
    "\n",
    "plt.plot(range(len(fractions)), fractions, label = \"all\", c = \"black\") # global value\n",
    "for dict, label, color in zip(result_dicts, sub_titles, colors):\n",
    "    x = dict[\"fractions\"]\n",
    "    x = [e if e != -1 else 0 for e in x]\n",
    "    plt.plot(range(len(x)), x, label = label)\n",
    "    \n",
    "plt.legend(loc = 'lower right')\n",
    "plt.xlabel(r'Sub-log $L_i$', size = 20)\n",
    "plt.ylabel(\"Fraction of Successful Users\", size = 20)\n",
    "if SAVE_ELEMENTS:\n",
    "    plt.savefig(\"company_fractions.png\")\n",
    "plt.show()\n",
    "\n",
    "lables = [\"max_steps\", \"min_gas\", \"max_final_gas\"]\n",
    "n = len(result_dicts)\n",
    "\n",
    "for j in range(3):\n",
    "    fig, axs = plt.subplots(1,n+1, figsize=(20, 6))\n",
    "    axs[n].scatter(range(len(result_dict_sequence[\"mc_results\"])), [r[j] for r in result_dict_sequence[\"mc_results\"]], s = 2, c = result_dict_sequence[\"colors\"])\n",
    "    axs[n].set_title(\"all\")\n",
    "    for i in range(n):\n",
    "        axs[i].scatter(range(len(result_dicts[i][\"mc_results\"])), [r[j] for r in result_dicts[i][\"mc_results\"]], s = 2, c = result_dicts[i][\"colors\"])\n",
    "        axs[i].set_title(sub_titles[i])\n",
    "    fig.suptitle(lables[j%3])\n",
    "    if SAVE_ELEMENTS:\n",
    "        plt.savefig(\"company\"+lables[j%3]+\".png\")\n",
    "    fig.show()\n",
    "\n",
    "    fig, axs = plt.subplots(1,n, figsize=(20, 6))\n",
    "    for i in range(n):\n",
    "        axs[i].scatter(range(len(result_dicts[i][\"mc_results\"])), [r[j+3] for r in result_dicts[i][\"mc_results\"]], s = 2, c = result_dicts[i][\"colors\"])\n",
    "        axs[i].set_title(sub_titles[i])\n",
    "    fig.suptitle(lables[j%3])\n",
    "    fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
